{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2642dba3",
   "metadata": {},
   "source": [
    "Uber Eats Delivery Times\n",
    "\n",
    "You are a data scientist working at Uber Eats, one of the worldâ€™s leading food delivery platforms. The company is focused on\n",
    "improving the accuracy of estimated delivery times to enhance customer satisfaction and operational efficiency. Predicting delivery\n",
    "time more accurately will not only improve the user experience but also help optimise routing and courier management.\n",
    "\n",
    "Your task is to develop a machine learning model that predicts the total delivery time (in minutes) for a food order, based on\n",
    "historical data. This model must use gradient descent to learn the best model parameters for predicting delivery times from the\n",
    "available features.\n",
    "\n",
    "Dataset Description\n",
    "\n",
    "You have access to the following data for previous orders:\n",
    "\n",
    "Order_ID: A unique identifier for each order.\n",
    "Distance_km: The delivery distance in kilometres.\n",
    "Weather: Weather conditions during the delivery.\n",
    "Traffic_Level: Traffic conditions category.\n",
    "Time_of_Day: The time of day when the delivery took place.\n",
    "Vehicle_Type: Type of vehicle used for delivery.\n",
    "Preparation_Time_min: The time required to prepare the order, measured in minutes.\n",
    "Courier_Experience_yrs: Experience of the courier/driver in years.\n",
    "Delivery_Time_min: The total delivery time in minutes (target variable - continuous).\n",
    "\n",
    "The dataset is named \"uber_eats.csv\" and can be downloaded from the \"Project Datasets\" folder on myLMS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d9dfb8",
   "metadata": {},
   "source": [
    "3.1. Explain why Linear Regression with Gradient Descent is suitable for predicting Uber Eats delivery time.\n",
    "(3 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf352c4",
   "metadata": {},
   "source": [
    "Delivery time is a continuous target and often roughly related to linear combinations of features (distance, prep time, traffic), so linear regression with an MSE loss is a natural, interpretable baseline.\n",
    "\n",
    "The MSE objective is convex and differentiable, so gradient descent reliably finds the global minimum and scales to larger datasets or many features where the normal equation is expensive or unstable.\n",
    "\n",
    "Gradient descent easily integrates feature standardisation and regularisation (L2/L1), improving convergence and preventing overfitting while keeping model coefficients interpretable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f09ff8",
   "metadata": {},
   "source": [
    "3.2. Implement the Linear Regression algorithm using Gradient Descent on the Uber Eats dataset to predict delivery time.\n",
    "\n",
    "Your implementation should include the following steps:\n",
    "\n",
    "Data cleaning (e.g., handling missing values)\n",
    "(3 marks)\n",
    "\n",
    "Encoding categorical variables\n",
    "(4 marks)\n",
    "\n",
    "Feature selection\n",
    "(5 marks)\n",
    "\n",
    "Feature standardisation\n",
    "(3 marks)\n",
    "\n",
    "Splitting data\n",
    "(2 marks)\n",
    "\n",
    "Training model using Gradient Descent\n",
    "(5 marks)\n",
    "\n",
    "Evaluating model performance using Mean Squared Error, mean absolute error, root mean squared error, and R2\n",
    "(5 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b76267b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['Distance_km', 'Preparation_Time_min', 'Weather_Snowy', 'Traffic_Level_Low', 'Courier_Experience_yrs', 'Weather_Rainy']\n",
      "MSE=98.62  MAE=6.74  RMSE=9.93  R2=0.780\n"
     ]
    }
   ],
   "source": [
    "#Question 3.2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# load\n",
    "df = pd.read_csv(\"uber_eats.csv\")\n",
    "\n",
    "# Data cleaning\n",
    "# drop id\n",
    "if \"Order_ID\" in df.columns:\n",
    "    df = df.drop(columns=[\"Order_ID\"])\n",
    "\n",
    "# fill numeric missing with median, categorical with mode\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "for c in num_cols:\n",
    "    df[c] = df[c].fillna(df[c].median())\n",
    "for c in cat_cols:\n",
    "    df[c] = df[c].fillna(df[c].mode().iloc[0])\n",
    "\n",
    "# Encoding categorical variables\n",
    "X = pd.get_dummies(df.drop(columns=[\"Delivery_Time_min\"]), drop_first=True)\n",
    "y = df[\"Delivery_Time_min\"].values\n",
    "\n",
    "# Feature selection \n",
    "# compute correlations \n",
    "corrs = pd.Series({col: abs(np.corrcoef(X[col].values, y)[0,1]) for col in X.columns})\n",
    "k = min(6, X.shape[1])\n",
    "selected = corrs.sort_values(ascending=False).head(k).index.tolist()\n",
    "X = X[selected]\n",
    "print(\"Selected features:\", selected)\n",
    "\n",
    "# Feature standardisation\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "#  Training model using Gradient Descent\n",
    "def train_gd(X, y, lr=0.01, epochs=2000):\n",
    "    n, m = X.shape\n",
    "    # add bias column\n",
    "    Xb = np.hstack([np.ones((n,1)), X])\n",
    "    w = np.zeros(m+1)\n",
    "    for epoch in range(epochs):\n",
    "        preds = Xb.dot(w)\n",
    "        grad = (2/n) * Xb.T.dot(preds - y)\n",
    "        w -= lr * grad\n",
    "    return w\n",
    "\n",
    "w = train_gd(X_train, y_train, lr=0.01, epochs=3000)\n",
    "\n",
    "# prediction helper\n",
    "def predict(w, X):\n",
    "    Xb = np.hstack([np.ones((X.shape[0],1)), X])\n",
    "    return Xb.dot(w)\n",
    "\n",
    "y_pred = predict(w, X_test)\n",
    "\n",
    "# Evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE={mse:.2f}  MAE={mae:.2f}  RMSE={rmse:.2f}  R2={r2:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
